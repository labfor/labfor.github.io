<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>DeepBurning</title>
    <meta name="description" content="Automatic generation of FPGA-based learning accelerators for the neural network family">
    
    
    <link rel="preload" href="/assets/css/0.styles.71acca2e.css" as="style"><link rel="preload" href="/assets/js/app.70176ff1.js" as="script"><link rel="preload" href="/assets/js/2.05a5bdd4.js" as="script"><link rel="preload" href="/assets/js/3.8fe30df6.js" as="script"><link rel="prefetch" href="/assets/js/10.af800fc3.js"><link rel="prefetch" href="/assets/js/11.a7a60f6a.js"><link rel="prefetch" href="/assets/js/12.8ccdb059.js"><link rel="prefetch" href="/assets/js/13.4ebe022b.js"><link rel="prefetch" href="/assets/js/14.8637aedb.js"><link rel="prefetch" href="/assets/js/15.ae32a4b0.js"><link rel="prefetch" href="/assets/js/16.db48ded1.js"><link rel="prefetch" href="/assets/js/17.e15bdab2.js"><link rel="prefetch" href="/assets/js/18.96823714.js"><link rel="prefetch" href="/assets/js/19.9d2c0d23.js"><link rel="prefetch" href="/assets/js/20.32e3ca65.js"><link rel="prefetch" href="/assets/js/21.ef311a9f.js"><link rel="prefetch" href="/assets/js/22.efaa70c8.js"><link rel="prefetch" href="/assets/js/23.d4605057.js"><link rel="prefetch" href="/assets/js/24.bef50e58.js"><link rel="prefetch" href="/assets/js/25.c153e3f7.js"><link rel="prefetch" href="/assets/js/26.2a5475a4.js"><link rel="prefetch" href="/assets/js/27.8695f3fa.js"><link rel="prefetch" href="/assets/js/28.a3792eac.js"><link rel="prefetch" href="/assets/js/29.52b35b48.js"><link rel="prefetch" href="/assets/js/30.33334f34.js"><link rel="prefetch" href="/assets/js/31.cbb334ac.js"><link rel="prefetch" href="/assets/js/32.82c1e6e1.js"><link rel="prefetch" href="/assets/js/33.2ca08221.js"><link rel="prefetch" href="/assets/js/34.f0b26b95.js"><link rel="prefetch" href="/assets/js/35.254b7974.js"><link rel="prefetch" href="/assets/js/36.f9a80ef9.js"><link rel="prefetch" href="/assets/js/37.9bc0673d.js"><link rel="prefetch" href="/assets/js/38.8b3034cb.js"><link rel="prefetch" href="/assets/js/39.87696277.js"><link rel="prefetch" href="/assets/js/4.b26a1bf9.js"><link rel="prefetch" href="/assets/js/40.098d7da2.js"><link rel="prefetch" href="/assets/js/41.2ef0469b.js"><link rel="prefetch" href="/assets/js/42.6bcee198.js"><link rel="prefetch" href="/assets/js/43.81c90bcf.js"><link rel="prefetch" href="/assets/js/44.981410ee.js"><link rel="prefetch" href="/assets/js/45.83f8a620.js"><link rel="prefetch" href="/assets/js/46.898eb698.js"><link rel="prefetch" href="/assets/js/47.4bb6e10d.js"><link rel="prefetch" href="/assets/js/48.4ecb5927.js"><link rel="prefetch" href="/assets/js/49.af65dbcd.js"><link rel="prefetch" href="/assets/js/5.709cf2c8.js"><link rel="prefetch" href="/assets/js/50.ef8a548c.js"><link rel="prefetch" href="/assets/js/51.978eed36.js"><link rel="prefetch" href="/assets/js/52.b450e70b.js"><link rel="prefetch" href="/assets/js/53.6722c684.js"><link rel="prefetch" href="/assets/js/54.0d9c809e.js"><link rel="prefetch" href="/assets/js/55.3a3f773d.js"><link rel="prefetch" href="/assets/js/56.36de60d7.js"><link rel="prefetch" href="/assets/js/57.4a30c66c.js"><link rel="prefetch" href="/assets/js/58.3ee6856e.js"><link rel="prefetch" href="/assets/js/59.44eb9d53.js"><link rel="prefetch" href="/assets/js/6.afc01e35.js"><link rel="prefetch" href="/assets/js/60.edfce79a.js"><link rel="prefetch" href="/assets/js/61.4c45d924.js"><link rel="prefetch" href="/assets/js/62.0eec2b83.js"><link rel="prefetch" href="/assets/js/63.e1ff3429.js"><link rel="prefetch" href="/assets/js/64.05b2596a.js"><link rel="prefetch" href="/assets/js/65.99c0aa68.js"><link rel="prefetch" href="/assets/js/66.ec012801.js"><link rel="prefetch" href="/assets/js/67.69afd052.js"><link rel="prefetch" href="/assets/js/68.45838412.js"><link rel="prefetch" href="/assets/js/69.220f7d97.js"><link rel="prefetch" href="/assets/js/7.0734f115.js"><link rel="prefetch" href="/assets/js/70.acabe687.js"><link rel="prefetch" href="/assets/js/71.36f2a9a0.js"><link rel="prefetch" href="/assets/js/72.2b7034b0.js"><link rel="prefetch" href="/assets/js/73.6a5e25c5.js"><link rel="prefetch" href="/assets/js/74.1f6c1c37.js"><link rel="prefetch" href="/assets/js/75.281b418a.js"><link rel="prefetch" href="/assets/js/76.81aee560.js"><link rel="prefetch" href="/assets/js/77.c761ae78.js"><link rel="prefetch" href="/assets/js/78.9bab21c0.js"><link rel="prefetch" href="/assets/js/79.b545ab46.js"><link rel="prefetch" href="/assets/js/8.92940364.js"><link rel="prefetch" href="/assets/js/80.0f329f3a.js"><link rel="prefetch" href="/assets/js/81.285e4f10.js"><link rel="prefetch" href="/assets/js/82.f6b1e7f5.js"><link rel="prefetch" href="/assets/js/83.a7b5921a.js"><link rel="prefetch" href="/assets/js/84.f0e6a26a.js"><link rel="prefetch" href="/assets/js/85.243f6bf8.js"><link rel="prefetch" href="/assets/js/86.6f29958c.js"><link rel="prefetch" href="/assets/js/87.dea33134.js"><link rel="prefetch" href="/assets/js/88.b798f02b.js"><link rel="prefetch" href="/assets/js/89.3f9d211d.js"><link rel="prefetch" href="/assets/js/9.cb8d6903.js"><link rel="prefetch" href="/assets/js/90.d3154a23.js"><link rel="prefetch" href="/assets/js/91.ad8445c3.js"><link rel="prefetch" href="/assets/js/92.39e72fd5.js"><link rel="prefetch" href="/assets/js/93.987b7ef2.js"><link rel="prefetch" href="/assets/js/94.c78ad323.js"><link rel="prefetch" href="/assets/js/95.3b5e21f8.js">
    <link rel="stylesheet" href="/assets/css/0.styles.71acca2e.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-exact-active router-link-active"><!----> <span class="site-name">DeepBurning</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/documentation/" class="nav-link">Documentation</a></div><div class="nav-item"><a href="/publications/" class="nav-link">Publications</a></div><div class="nav-item"><a href="/about/" class="nav-link">About</a></div><div class="nav-item"><a href="https://github.com/labfor/DeepBurning" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Download
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/documentation/" class="nav-link">Documentation</a></div><div class="nav-item"><a href="/publications/" class="nav-link">Publications</a></div><div class="nav-item"><a href="/about/" class="nav-link">About</a></div><div class="nav-item"><a href="https://github.com/labfor/DeepBurning" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Download
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav>  <!----> </aside> <main aria-labelledby="main-title" class="home"><header class="hero"><img src="/logo.png" alt="hero"> <!----> <p class="description">
      Automatic generation of FPGA-based learning accelerators for the neural network family
    </p> <!----></header> <!----> <div class="theme-default-content custom content__default"><br> <h2 id="introduction"><a href="#introduction" class="header-anchor">#</a> Introduction</h2> <p>DeepBurning [1] is an end-to-end neural network acceleration design tool that generates both customized neural network model and neural processing unit (NPU) for a specialized learning task on FPGAs. The overview of DeepBurning is shown in Figure 1. It only requires the dataset of the target application and high-level design constraints such as total resource budget to produce a unified optimized acceleration solution targeting at a typical heterogeneous CPU+FPGA architecture that can be immediately deployed, while the application developers can focus on the application development without dealing with the complex neural network model designing nor the low-level accelerator parameter tuning. Particularly, we propose an efficient co-designed autoML search framework named YOSO [2] that seeks to optimize the neural network architecture and the NPU parameters at the same time. Note that DeepBurning relies on a pre-built NPU template that allows flexible configuration and customization. The template is supposed to be developed by skilled hardware designers to ensure efficient hardware implementation.</p> <div align="center"><img src="/assets/img/deepburning.3b138199.svg" width="100%" height="100%"> <br> <div style="display:inline-block;color:#999;padding:2px;"> Figure 1 DeepBuring Overview</div></div> <p>DeepBurning is under active development. The major components including YOSO and NPU compilation are already in use while the automatic NPU generation based on the pre-built template still needs quite some handcrafted adjustment. We will put it online soon when we get it ready. Currently, we only allow the users to compile neural network models to a specific NPU configuration.</p> <br> <h2 id="key-features"><a href="#key-features" class="header-anchor">#</a> Key features</h2> <p>Supported</p> <ul><li>Given high-level design constraints, YOSO can be used to search for the optimized neural network architecture and NPU configuration.</li> <li>Neural network models described in Prototxt can be compiled to instructions and then deployed on the pre-built NPU. Currently, we just provide some pre-compiled neural networks and we will offer a free on-line compiler later.</li> <li>A typical NPU with 2D array computing architecture is provided as a netlist. Its architecture is shown in Figure 2. It consists of 128 KB I/O buffer that can be allocated for input and output dynamically and supports data prefetch to hide the external memory access overhead. It covers a large number of typical operations utilized in typical neural networks and relevant image processing operations, so it supports more than 30 neural networks. The supported operations and neural network models are listed in Table 1.</li> <li>The generated accelerators and drivers can be utilized in Xilinx Zynq 7000 devices. Particularly, the design is verified on ZC706 and MZ7100. The corresponding Linux kernel and root file system is also provided.</li></ul> <div align="center"><img src="/assets/img/npu.eaf61c51.svg" width="60%" height="60%"> <br> <div style="display:inline-block;color:#999;padding:2px;">Figure 2 NPU Architecture</div></div> <br> <div align="center"><div style="display:inline-block;color:#999;padding:2px;"> Table 1 Supported NPU operations and neural network models</div></div> <table><thead><tr><th style="text-align:center;">Neural network operations</th> <th style="text-align:center;">General computing operations</th> <th style="text-align:center;">Neural network models</th></tr></thead> <tbody><tr><td style="text-align:center;">Convolution, deconvolution, 3D convolution, grouped convolution, Full connection, Softmax, Elementwise, Concat, Reorganization, Batch normalization, Pooling (average, max) Activation function (Relu, Prelu, Leaky Relu, tanh, Sigmoid, …)</td> <td style="text-align:center;">Matrix-matrix multiplication, Matrix-vector multiplication, Dot-production, Cosine distance, Feature scaling</td> <td style="text-align:center;">GoogleNet, DenseNet, VGG, ResNet, MobileNet, SqueezeNet, DCGAN, LSTM, MTCNN, Hourglass, …</td></tr></tbody></table> <br> <h2 id="performance-evaluation"><a href="#performance-evaluation" class="header-anchor">#</a> Performance evaluation</h2> <p>We measure the performance and the FPGA resource consumption on MZ7100 board which includes a Zynq 7100 FPGA chip. The NPU kernel runs at 100 MHz and it can be optimized up to 200 MHz. The measured fps on ImageNet is shown in Table 2 and the total FPGA resource overhead is presented in Table 3.</p> <div align="center"><div style="display:inline-block;color:#999;padding:8px;"> Table 2 Performance Evaluation</div> <br> <table style="display:inline;"><tr><th>  Neural Network Models  </th> <th>  Fps (100 MHz)</th> <th>  Fps (200 MHz)  </th></tr> <tr><td>ResNet18</td> <td> 5 fps</td> <td> 10 fps  </td></tr> <tr><td>YOLO v2  </td> <td> 2.5 fps</td> <td> 4.5 fps</td></tr> <tr><td>MTCNN+Facenet</td> <td> 2 fps</td> <td> 4.2 fps</td></tr></table></div> <br> <br> <div align="center"><div style="display:inline-block;color:#999;padding:8px;"> Table 3 NPU resource consumption on MZ7100</div> <br> <table style="display:inline;"><tr><th>LUT</th> <th>BRAM</th> <th>DSP</th> <th>FF</th> <th>LUTRAM</th></tr> <tr><td>115561</td> <td>193</td> <td>359</td> <td>56420</td> <td>911</td></tr> <tr><td>67%</td> <td>39%</td> <td>40%</td> <td>16%</td> <td>1%</td></tr></table></div> <br> <h2 id="demo-video"><a href="#demo-video" class="header-anchor">#</a> Demo video</h2> <p>We also present two application videos in which we utilize DeepBurning to generate the acceleration solution on MZ7100 board.</p> <ul><li><p>Object detection: The input figures are captured by the camera and processed on NPU deployed on the FPGA. While the figures selected from ImageNet and displayed on screen with another computer.
</p><div align="center"><video src="/assets/media/object.b68137b4.mp4" controls="controls" width="75%" height="75%"></video></div><p></p></li> <li><p>DCGAN based face generation: The faces are generated with DCGAN which is a typical generative neural network.
</p><div align="center"><video src="/assets/media/face.1419adca.mp4" controls="controls" width="75%" height="75%"></video></div> <br><p></p></li></ul> <h3 id="contact"><a href="#contact" class="header-anchor">#</a> Contact</h3> <p><strong>Prof. Ying Wang (wangying2009@ict.ac.cn)</strong></p></div> <div class="footer">
    MIT Licensed
  </div></main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.70176ff1.js" defer></script><script src="/assets/js/2.05a5bdd4.js" defer></script><script src="/assets/js/3.8fe30df6.js" defer></script>
  </body>
</html>
